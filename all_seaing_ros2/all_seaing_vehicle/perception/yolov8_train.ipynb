{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train the model using Yolov8 and Roboflow\n",
    "\n",
    "Reference: https://blog.roboflow.com/how-to-train-yolov8-on-a-custom-dataset/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.232 ðŸš€ Python-3.10.12 torch-2.2.0+cu121 CPU (AMD Ryzen 9 6900HS with Radeon Graphics)\n",
      "Setup complete âœ… (16 CPUs, 14.9 GB RAM, 77.9/97.5 GB disk)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# if not installed run: pip install ultralytics\n",
    "import ultralytics\n",
    "print(ultralytics.checks())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.0.232, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Buoy-Labeling-Full-1 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15631/15631 [00:02<00:00, 7681.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Buoy-Labeling-Full-1 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2006/2006 [00:00<00:00, 11454.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# if not installed run: pip install roboflow\n",
    "# if you have a weird 'appengine' error run this: pip install urllib3==2.0.7\n",
    "# other errors, run through chat gpt\n",
    "# this was copied from exporting the dataset on roboflow with 'yolov8'\n",
    "\n",
    "from roboflow import Roboflow\n",
    "\n",
    "rf = Roboflow(api_key=\"tG58USi1UKOd6l1rkJEw\") # Private Key for Team\n",
    "project = rf.workspace(\"arcturus-gx59n\").project(\"buoy-labeling-full\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Reference: @misc{\n",
    "roboboat-comp-2024_dataset,\n",
    "title = { RoboBoat Comp 2024 Dataset },\n",
    "type = { Open Source Dataset },\n",
    "author = { Cornell AutoBoat },\n",
    "howpublished = { '\\'url{ https://universe.roboflow.com/cornell-autoboat-fz9yv/roboboat-comp-2024 } },\n",
    "url = { https://universe.roboflow.com/cornell-autoboat-fz9yv/roboboat-comp-2024 },\n",
    "journal = { Roboflow Universe },\n",
    "publisher = { Roboflow },\n",
    "year = { 2024 },\n",
    "month = { feb },\n",
    "note = { visited on 2024-03-17 },\n",
    "}\"\"\"\n",
    "\n",
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"UEdSpNWdrrkxTs2Uz6JD\")\n",
    "project = rf.workspace(\"cornell-autoboat-fz9yv\").project(\"roboboat-comp-2024\")\n",
    "version = project.version(4)\n",
    "dataset = version.download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training of the model with the correct location to the data.yaml and custom settings (could take a while)\n",
    "# This assumes data folder is in perception folder and this document is in perception folder\n",
    "data_folder = 'Buoy-Labeling-Full-1'\n",
    "\n",
    "imgsz = 640\n",
    "\n",
    "model= 'yolov8n.pt' # the other models are too big\n",
    "\n",
    "# ! symbol lets you run command line interface commands (terminal commands) \n",
    "# Run this in command line if you get errors\n",
    "# replace data.location with the name of the file folder\n",
    "# WARNING: This will take a while and consume a lot of computer resources\n",
    "!yolo task=detect \\\n",
    "    mode=train \\\n",
    "    model=yolov8s.pt \\\n",
    "    data={data.location}/data.yaml \\\n",
    "    epochs=25 \\\n",
    "    imgsz=640 \\\n",
    "    plots=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation of training results\n",
    "\n",
    "!yolo task=detect \\\n",
    "    mode=val \\\n",
    "    model={HOME}/runs/detect/train/weights/best.pt \\\n",
    "    data={dataset.location}/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arthurdls/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/arthurdls/.local/bin/yolo\", line 8, in <module>\n",
      "    sys.exit(entrypoint())\n",
      "  File \"/home/arthurdls/.local/lib/python3.10/site-packages/ultralytics/cfg/__init__.py\", line 423, in entrypoint\n",
      "    model = YOLO(model, task=task)\n",
      "  File \"/home/arthurdls/.local/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 94, in __init__\n",
      "    self._load(model, task)\n",
      "  File \"/home/arthurdls/.local/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 146, in _load\n",
      "    self.model, self.ckpt = attempt_load_one_weight(weights)\n",
      "  File \"/home/arthurdls/.local/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 639, in attempt_load_one_weight\n",
      "    ckpt, weight = torch_safe_load(weight)  # load ckpt\n",
      "  File \"/home/arthurdls/.local/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 578, in torch_safe_load\n",
      "    return torch.load(file, map_location='cpu'), file  # load\n",
      "  File \"/home/arthurdls/.local/lib/python3.10/site-packages/torch/serialization.py\", line 998, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/home/arthurdls/.local/lib/python3.10/site-packages/torch/serialization.py\", line 445, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/home/arthurdls/.local/lib/python3.10/site-packages/torch/serialization.py\", line 426, in __init__\n",
      "    super().__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '{HOME}/runs/detect/train/weights/best.pt'\n"
     ]
    }
   ],
   "source": [
    "# predict using model\n",
    "\n",
    "!yolo task=detect \\\n",
    "    mode=predict \\\n",
    "    model={HOME}/runs/detect/train/weights/best.pt \\\n",
    "    conf=0.25 \\\n",
    "    source={dataset.location}/test/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 red-buoy, 1 yellow-buoy, 1 yellow-duck, 26.3ms\n",
      "1: 480x640 2 green-buoys, 1 red-buoy, 1 yellow-buoy, 26.3ms\n",
      "2: 480x640 2 green-buoys, 1 red-buoy, 1 yellow-buoy, 1 yellow-duck, 26.3ms\n",
      "3: 480x640 3 green-buoys, 1 red-buoy, 1 yellow-buoy, 26.3ms\n",
      "Speed: 3.5ms preprocess, 26.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "res = ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'black-buoy', 1: 'blue-buoy', 2: 'blue-cross', 3: 'green-buoy', 4: 'green-column-buoy', 5: 'red-buoy', 6: 'red-column-buoy', 7: 'red-dot', 8: 'yellow-buoy', 9: 'yellow-duck'}\n",
      "obb: None\n",
      "orig_img: array([[[ 35,   4, 213],\n",
      "        [ 34,   3, 212],\n",
      "        [ 37,   6, 215],\n",
      "        ...,\n",
      "        [ 62,  81, 102],\n",
      "        [ 42,  61,  82],\n",
      "        [ 60,  79, 100]],\n",
      "\n",
      "       [[ 38,   7, 216],\n",
      "        [ 36,   5, 214],\n",
      "        [ 38,   7, 216],\n",
      "        ...,\n",
      "        [ 64,  83, 104],\n",
      "        [ 60,  79, 100],\n",
      "        [ 55,  74,  95]],\n",
      "\n",
      "       [[ 39,   8, 217],\n",
      "        [ 44,  13, 222],\n",
      "        [ 39,   8, 217],\n",
      "        ...,\n",
      "        [ 64,  83, 104],\n",
      "        [ 59,  78,  99],\n",
      "        [ 57,  76,  97]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[150, 165, 137],\n",
      "        [148, 163, 135],\n",
      "        [147, 162, 134],\n",
      "        ...,\n",
      "        [125, 140, 109],\n",
      "        [120, 135, 104],\n",
      "        [129, 144, 113]],\n",
      "\n",
      "       [[147, 162, 134],\n",
      "        [147, 162, 134],\n",
      "        [145, 160, 132],\n",
      "        ...,\n",
      "        [133, 148, 117],\n",
      "        [123, 138, 107],\n",
      "        [118, 133, 102]],\n",
      "\n",
      "       [[150, 165, 137],\n",
      "        [148, 163, 135],\n",
      "        [147, 162, 134],\n",
      "        ...,\n",
      "        [134, 149, 118],\n",
      "        [134, 149, 118],\n",
      "        [131, 146, 115]]], dtype=uint8)\n",
      "orig_shape: (3000, 4000)\n",
      "path: 'arcturus_test_image_1.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs/detect/predict'\n",
      "speed: {'preprocess': 3.4845471382141113, 'inference': 26.294291019439697, 'postprocess': 0.5663633346557617}\n",
      "res = ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'black-buoy', 1: 'blue-buoy', 2: 'blue-cross', 3: 'green-buoy', 4: 'green-column-buoy', 5: 'red-buoy', 6: 'red-column-buoy', 7: 'red-dot', 8: 'yellow-buoy', 9: 'yellow-duck'}\n",
      "obb: None\n",
      "orig_img: array([[[187, 188, 184],\n",
      "        [188, 189, 185],\n",
      "        [188, 189, 185],\n",
      "        ...,\n",
      "        [178, 179, 177],\n",
      "        [177, 178, 176],\n",
      "        [179, 180, 178]],\n",
      "\n",
      "       [[187, 188, 184],\n",
      "        [188, 189, 185],\n",
      "        [189, 190, 186],\n",
      "        ...,\n",
      "        [176, 177, 175],\n",
      "        [177, 178, 176],\n",
      "        [179, 180, 178]],\n",
      "\n",
      "       [[188, 189, 185],\n",
      "        [190, 191, 187],\n",
      "        [191, 192, 188],\n",
      "        ...,\n",
      "        [173, 174, 172],\n",
      "        [176, 177, 175],\n",
      "        [178, 179, 177]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[182, 193, 161],\n",
      "        [180, 191, 159],\n",
      "        [179, 190, 158],\n",
      "        ...,\n",
      "        [182, 191, 165],\n",
      "        [183, 192, 166],\n",
      "        [183, 192, 166]],\n",
      "\n",
      "       [[182, 193, 161],\n",
      "        [181, 192, 160],\n",
      "        [181, 192, 160],\n",
      "        ...,\n",
      "        [183, 192, 166],\n",
      "        [184, 193, 167],\n",
      "        [183, 192, 166]],\n",
      "\n",
      "       [[180, 191, 159],\n",
      "        [181, 192, 160],\n",
      "        [181, 192, 160],\n",
      "        ...,\n",
      "        [183, 192, 166],\n",
      "        [184, 193, 167],\n",
      "        [182, 191, 165]]], dtype=uint8)\n",
      "orig_shape: (3000, 4000)\n",
      "path: 'arcturus_test_image_2.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs/detect/predict'\n",
      "speed: {'preprocess': 3.4845471382141113, 'inference': 26.294291019439697, 'postprocess': 0.5663633346557617}\n",
      "res = ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'black-buoy', 1: 'blue-buoy', 2: 'blue-cross', 3: 'green-buoy', 4: 'green-column-buoy', 5: 'red-buoy', 6: 'red-column-buoy', 7: 'red-dot', 8: 'yellow-buoy', 9: 'yellow-duck'}\n",
      "obb: None\n",
      "orig_img: array([[[178, 179, 175],\n",
      "        [179, 180, 176],\n",
      "        [180, 181, 177],\n",
      "        ...,\n",
      "        [161, 164, 162],\n",
      "        [160, 163, 161],\n",
      "        [159, 162, 160]],\n",
      "\n",
      "       [[178, 179, 175],\n",
      "        [179, 180, 176],\n",
      "        [180, 181, 177],\n",
      "        ...,\n",
      "        [159, 162, 160],\n",
      "        [159, 162, 160],\n",
      "        [160, 163, 161]],\n",
      "\n",
      "       [[178, 179, 175],\n",
      "        [179, 180, 176],\n",
      "        [180, 181, 177],\n",
      "        ...,\n",
      "        [156, 159, 157],\n",
      "        [157, 160, 158],\n",
      "        [160, 163, 161]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[168, 178, 148],\n",
      "        [168, 178, 148],\n",
      "        [168, 178, 148],\n",
      "        ...,\n",
      "        [168, 177, 151],\n",
      "        [170, 179, 153],\n",
      "        [176, 185, 159]],\n",
      "\n",
      "       [[171, 181, 151],\n",
      "        [171, 181, 151],\n",
      "        [170, 180, 150],\n",
      "        ...,\n",
      "        [171, 180, 154],\n",
      "        [169, 178, 152],\n",
      "        [172, 181, 155]],\n",
      "\n",
      "       [[173, 183, 153],\n",
      "        [173, 183, 153],\n",
      "        [173, 183, 153],\n",
      "        ...,\n",
      "        [175, 184, 158],\n",
      "        [172, 181, 155],\n",
      "        [172, 181, 155]]], dtype=uint8)\n",
      "orig_shape: (3000, 4000)\n",
      "path: 'arcturus_test_image_3.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs/detect/predict'\n",
      "speed: {'preprocess': 3.4845471382141113, 'inference': 26.294291019439697, 'postprocess': 0.5663633346557617}\n",
      "res = ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'black-buoy', 1: 'blue-buoy', 2: 'blue-cross', 3: 'green-buoy', 4: 'green-column-buoy', 5: 'red-buoy', 6: 'red-column-buoy', 7: 'red-dot', 8: 'yellow-buoy', 9: 'yellow-duck'}\n",
      "obb: None\n",
      "orig_img: array([[[173, 174, 170],\n",
      "        [175, 176, 172],\n",
      "        [173, 174, 170],\n",
      "        ...,\n",
      "        [126, 133, 130],\n",
      "        [119, 126, 123],\n",
      "        [110, 117, 114]],\n",
      "\n",
      "       [[171, 172, 168],\n",
      "        [172, 173, 169],\n",
      "        [172, 173, 169],\n",
      "        ...,\n",
      "        [121, 128, 125],\n",
      "        [114, 121, 118],\n",
      "        [107, 114, 111]],\n",
      "\n",
      "       [[168, 169, 165],\n",
      "        [168, 169, 165],\n",
      "        [169, 170, 166],\n",
      "        ...,\n",
      "        [116, 123, 120],\n",
      "        [109, 116, 113],\n",
      "        [104, 111, 108]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[161, 172, 122],\n",
      "        [160, 171, 121],\n",
      "        [160, 170, 124],\n",
      "        ...,\n",
      "        [153, 165, 117],\n",
      "        [154, 164, 121],\n",
      "        [154, 164, 121]],\n",
      "\n",
      "       [[164, 175, 125],\n",
      "        [163, 174, 124],\n",
      "        [161, 171, 125],\n",
      "        ...,\n",
      "        [152, 164, 116],\n",
      "        [152, 162, 119],\n",
      "        [153, 163, 120]],\n",
      "\n",
      "       [[162, 173, 123],\n",
      "        [164, 175, 125],\n",
      "        [163, 173, 127],\n",
      "        ...,\n",
      "        [150, 162, 114],\n",
      "        [150, 160, 117],\n",
      "        [152, 162, 119]]], dtype=uint8)\n",
      "orig_shape: (3000, 4000)\n",
      "path: 'arcturus_test_image_4.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs/detect/predict'\n",
      "speed: {'preprocess': 3.4845471382141113, 'inference': 26.294291019439697, 'postprocess': 0.5663633346557617}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "model = YOLO(\"runs/detect/train_roboboat/weights/best.pt\")\n",
    "\n",
    "# results = model.predict(source=\"RoboBoat-Comp-2024-4/test/images\")\n",
    "results = model([\"arcturus_test_image_1.jpg\",\n",
    "                 \"arcturus_test_image_2.jpg\",\n",
    "                 \"arcturus_test_image_3.jpg\",\n",
    "                 \"arcturus_test_image_4.jpg\"])\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"res = {result}\")\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    result.save(filename=f'result_{i}.jpg')  # specify filename to save to disk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
